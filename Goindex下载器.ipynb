{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Goindex下载器.ipynb","provenance":[{"file_id":"1tmsLGuswIZIZ_oM35EMW8TbJ6pQPt1rY","timestamp":1587628943426}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"3bCnUMUg_SoT","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Px-KV1aN9X98","colab_type":"code","colab":{}},"source":["!apt-get update\n","!apt install chromium-chromedriver\n","!pip install selenium\n","!pip install bs4"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7opUlUe19fqG","colab_type":"code","colab":{}},"source":["import os\n","import time\n","import sys\n","import requests\n","from selenium import webdriver\n","from selenium.webdriver.chrome.options import Options\n","from bs4 import BeautifulSoup\n","from collections import OrderedDict \n","chromedriver = \"/usr/bin/chromedriver\"\n","chrome_options = Options()\n","chrome_options.add_argument('--headless')\n","chrome_options.add_argument('--no-sandbox')\n","chrome_options.add_argument('--disable-dev-shm-usage')\n","d = webdriver.Chrome(chromedriver,options=chrome_options)\n","destinationDir = \"/content/drive/Shared drives/PankajCCSF/test\"\n","url = 'https://edu.tuts.workers.dev/Udacity%20-%20Collections%20[300%20GB]/Nanodegrees/Business%20Analytics%20Nanodegree%20v2.0.0/'\n","d.get(url)\n","time.sleep(7)\n","page_html = d.page_source\n","\n","#crawler starts here\n","def crawler(page_html):\n","    folderDic = {}\n","    fileDic = {}\n","    soup = BeautifulSoup(page_html, 'html.parser')\n","    for fileFolders in soup.select('li.mdui-list-item a'):\n","        if (fileFolders.contents[1].text.find(\"folder_open\") > -1):\n","            tempFolderName = fileFolders.contents[1].text\n","            folderName = tempFolderName.replace(\"folder_open\", \"\").strip().strip().replace(\"/\",\"\")\n","            folderDic[folderName] = \"https://edu.tuts.workers.dev\" + fileFolders['href']\n","        else:\n","            tempFileName = fileFolders.contents[1].text\n","            fileName = tempFileName.replace(\"insert_drive_file\", \"\").strip().replace(\"/\",\"\")\n","            fileDic[fileName] = \"https://edu.tuts.workers.dev\" + fileFolders['href'].replace(\"?a=view\", \"\")\n","\n","    return folderDic,fileDic\n","    #crawler ends here\n","\n","folderDictonary,fileDictonary = crawler(page_html)\n","for folderName, folderUrl in folderDictonary.items():\n","  saveDir = os.path.join(destinationDir,folderName)\n","  if(os.path.exists(saveDir)):\n","    print(\"skipping => \" + saveDir)\n","    continue\n","  print(\"Downloading =>\" + saveDir)  \n","  try:\n","    os.mkdir(saveDir)\n","  except Exception as e:\n","    pass  \n","  d.get(folderUrl)\n","  time.sleep(9)\n","  lvlTwoSource = d.page_source\n","  folderDictonaryLvlTwo,fileDictonaryLvlTwo = crawler(lvlTwoSource)\n","  if(len(folderDictonaryLvlTwo)==0 and len(fileDictonaryLvlTwo)==0):\n","    print(saveDir)\n","    print(\"Content might not have been downloaded for above folder . Please consider increasing sleep time on line number 50 and delete the empty folder\")\n","  # sys.exit()\n","  for folderNameTwo, folderUrlTwo in folderDictonaryLvlTwo.items(): \n","    lvlTwoSaveDir = os.path.join(saveDir,folderNameTwo)\n","    try:\n","      os.mkdir(lvlTwoSaveDir)\n","    except Exception as e:\n","      pass\n","\n","  #actual file processing\n","\n","  for fileNameTwo, fileUrlTwo in fileDictonaryLvlTwo.items(): \n","    if(os.path.exists(os.path.join(saveDir,fileNameTwo))):\n","      print(\"skipping => \" + os.path.join(saveDir,fileNameTwo))\n","      continue \n","    r = requests.get(fileUrlTwo,stream=True)\n","    with open(os.path.join(saveDir,fileNameTwo),\"ab+\") as f:\n","      f.write(r.content)\n","\n","  # print(folderName + \"=>\" + folderUrl)\n","\n","for fileNameMainDir, fileUrlMain in fileDictonary.items():\n","  # if(os.path.exists(os.path.join(destinationDir,fileNameMainDir))):\n","  #   print(\"skipping =>\" + os.path.join(destinationDir,fileNameMainDir))  \n","  #   continue\n","  r = requests.get(fileUrlMain,stream=True)\n","  with open(os.path.join(destinationDir,fileNameMainDir),\"ab+\") as f:\n","    print(\"Downloading =>\" + os.path.join(destinationDir,fileNameMainDir))\n","    f.write(r.content)\n"],"execution_count":0,"outputs":[]}]}